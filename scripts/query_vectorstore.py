#!/usr/bin/env python3
"""
Vector Store ì¡°íšŒ ìŠ¤í¬ë¦½íŠ¸
ì¸ë±ì‹±ëœ í‘œì¤€ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ì¡°íšŒ
"""
import sys
from pathlib import Path
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# .env íŒŒì¼ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv(dotenv_path=project_root / '.env')

from src.project_generator.workflows.common.rag_retriever import RAGRetriever
from src.project_generator.config import Config


def list_all_documents(category_filter: str = None):
    """Vector Storeì— ì €ì¥ëœ ëª¨ë“  ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ"""
    retriever = RAGRetriever()
    
    if not retriever._initialized or not retriever.vectorstore:
        print("âŒ Vector Storeê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    try:
        # ChromaDBì—ì„œ ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
        collection = retriever.vectorstore._collection
        count = collection.count()
        
        print(f"ğŸ“Š Vector Storeì— ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {count}ê°œ")
        if category_filter:
            print(f"ğŸ” ì¹´í…Œê³ ë¦¬ í•„í„°: {category_filter}\n")
        else:
            print()
        
        if count == 0:
            print("âš ï¸  ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # í•„í„° ì ìš© ì—¬ë¶€ì— ë”°ë¼ ê°€ì ¸ì˜¤ê¸°
        if category_filter:
            results = collection.get(
                limit=count,
                where={"category": category_filter}
            )
        else:
            results = collection.get(limit=count)
        
        print("=" * 80)
        print("ğŸ“š ì €ì¥ëœ ë¬¸ì„œ ëª©ë¡ (ì „ì²´):")
        print("=" * 80)
        
        # ì‹¤ì œ í•„í„°ë§ëœ ê²°ê³¼ ê°œìˆ˜
        filtered_count = len(results.get('ids', []))
        
        for i, (doc_id, metadata, document) in enumerate(zip(
            results.get('ids', []),
            results.get('metadatas', []),
            results.get('documents', [])
        ), 1):
            print(f"\n[{i}/{filtered_count}] ID: {doc_id}")
            print(f"    ì¶œì²˜: {Path(metadata.get('source', '')).name}")
            if metadata.get('sheet'):
                print(f"    ì‹œíŠ¸: {metadata.get('sheet')}")
            if metadata.get('section'):
                print(f"    ì„¹ì…˜: {metadata.get('section')}")
            
            # ë¬¸ì„œ ë‚´ìš© ì „ì²´ í‘œì‹œ
            print(f"    ë‚´ìš©:")
            # ë‚´ìš©ì´ ê¸¸ë©´ ì¤„ë°”ê¿ˆí•˜ì—¬ í‘œì‹œ
            content_lines = document.split('\n')
            if len(content_lines) > 10:
                # ì²˜ìŒ 10ì¤„ + ë§ˆì§€ë§‰ 3ì¤„ í‘œì‹œ
                for line in content_lines[:10]:
                    print(f"      {line}")
                print(f"      ... (ì¤‘ê°„ {len(content_lines) - 13}ì¤„ ìƒëµ) ...")
                for line in content_lines[-3:]:
                    print(f"      {line}")
            else:
                for line in content_lines:
                    print(f"      {line}")
            
            # êµ¬ì¡°í™”ëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ í‘œì‹œ
            if metadata.get('structured_data'):
                try:
                    structured = json.loads(metadata.get('structured_data'))
                    print(f"    êµ¬ì¡°í™”ëœ ë°ì´í„°:")
                    print(f"    {json.dumps(structured, ensure_ascii=False, indent=4)}")
                except Exception as e:
                    print(f"    êµ¬ì¡°í™”ëœ ë°ì´í„° (íŒŒì‹± ì‹¤íŒ¨): {metadata.get('structured_data')[:200]}...")
        
        print(f"\n{'=' * 80}")
        if category_filter:
            print(f"âœ… ì´ {filtered_count}ê°œ ë¬¸ì„œ ì¡°íšŒ ì™„ë£Œ (ì¹´í…Œê³ ë¦¬: {category_filter}, ì „ì²´: {count}ê°œ)")
        else:
            print(f"âœ… ì´ {filtered_count}ê°œ ë¬¸ì„œ ì¡°íšŒ ì™„ë£Œ")
        print(f"{'=' * 80}")
        
    except Exception as e:
        print(f"âŒ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()


def search_documents(query: str, k: int = 5):
    """ì¿¼ë¦¬ë¡œ ë¬¸ì„œ ê²€ìƒ‰"""
    retriever = RAGRetriever()
    
    if not retriever._initialized or not retriever.vectorstore:
        print("âŒ Vector Storeê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'")
    print(f"ğŸ“Š ë°˜í™˜í•  ê²°ê³¼ ìˆ˜: {k}ê°œ\n")
    
    try:
        results = retriever.search_company_standards(query, k=k)
        
        if not results:
            print("âš ï¸  ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print("=" * 80)
        print(f"ğŸ“š ê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê°œ):")
        print("=" * 80)
        
        for i, result in enumerate(results, 1):
            content = result.get("content", "")
            metadata = result.get("metadata", {})
            
            print(f"\n[{i}] ì¶œì²˜: {Path(metadata.get('source', '')).name}")
            print(f"    ë‚´ìš©:")
            print(f"    {content}")
            
            if metadata.get('structured_data'):
                try:
                    structured = json.loads(metadata.get('structured_data'))
                    print(f"    êµ¬ì¡°í™”ëœ ë°ì´í„°:")
                    print(f"    {json.dumps(structured, ensure_ascii=False, indent=4)}")
                except:
                    pass
        
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Vector Store ì¡°íšŒ ë° ê²€ìƒ‰')
    parser.add_argument(
        '--list',
        action='store_true',
        help='ëª¨ë“  ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ'
    )
    parser.add_argument(
        '--search',
        type=str,
        default=None,
        help='ê²€ìƒ‰ ì¿¼ë¦¬'
    )
    parser.add_argument(
        '--k',
        type=int,
        default=5,
        help='ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸: 5)'
    )
    parser.add_argument(
        '--category',
        type=str,
        default=None,
        help='ì¹´í…Œê³ ë¦¬ í•„í„° (ì˜ˆ: table_name, column_name)'
    )
    
    args = parser.parse_args()
    
    print("ğŸš€ Vector Store ì¡°íšŒ ë„êµ¬")
    print(f"ğŸ“ Vector Store ê²½ë¡œ: {Config.VECTORSTORE_PATH}\n")
    
    if args.list:
        list_all_documents(category_filter=args.category)
    elif args.search:
        search_documents(args.search, args.k)
    else:
        print("ì‚¬ìš©ë²•:")
        print("  ëª¨ë“  ë¬¸ì„œ ëª©ë¡: python scripts/query_vectorstore.py --list")
        print("  ì¹´í…Œê³ ë¦¬ë³„ ëª©ë¡: python scripts/query_vectorstore.py --list --category table_name")
        print("  ê²€ìƒ‰: python scripts/query_vectorstore.py --search 'Order aggregate table naming standard'")
        print("  ê²€ìƒ‰ (ê²°ê³¼ ìˆ˜ ì§€ì •): python scripts/query_vectorstore.py --search 'Order' --k 10")


if __name__ == '__main__':
    main()

