import asyncio
import concurrent.futures
import threading
from datetime import datetime
from dotenv import load_dotenv
load_dotenv()

from project_generator.utils import JobUtil, DecentralizedJobManager
from project_generator.systems.firebase_system import FirebaseSystem
from project_generator.config import Config
from project_generator.run_healcheck_server import run_healcheck_server
from project_generator.simple_autoscaler import start_autoscaler
from project_generator.utils.logging_util import LoggingUtil

# Workflow imports
from project_generator.workflows.user_story.user_story_generator import UserStoryWorkflow
from project_generator.workflows.summarizer.requirements_summarizer import RequirementsSummarizerWorkflow
from project_generator.workflows.bounded_context.bounded_context_generator import BoundedContextWorkflow
from project_generator.workflows.sitemap.command_readmodel_extractor import create_command_readmodel_workflow
from project_generator.workflows.sitemap.sitemap_generator import create_sitemap_workflow

# ì „ì—­ job_manager ì¸ìŠ¤í„´ìŠ¤
_current_job_manager: DecentralizedJobManager = None

async def main():
    """ë©”ì¸ í•¨ìˆ˜ - Flask ì„œë²„, Job ëª¨ë‹ˆí„°ë§, ìë™ ìŠ¤ì¼€ì¼ëŸ¬ ë™ì‹œ ì‹œì‘"""
    
    flask_thread = None
    restart_count = 0
    
    while True:
        tasks = []
        job_manager = None
        
        try:
            
            # Flask ì„œë²„ ì‹œì‘ (ì²« ì‹¤í–‰ì‹œì—ë§Œ)
            if flask_thread is None:
                flask_thread = threading.Thread(target=run_healcheck_server, daemon=True)
                flask_thread.start()
                LoggingUtil.info("main", "Flask ì„œë²„ê°€ í¬íŠ¸ 2024ì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
                LoggingUtil.info("main", "í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸: http://localhost:2024/ok")

            if restart_count > 0:
                LoggingUtil.info("main", f"ë©”ì¸ í•¨ìˆ˜ ì¬ì‹œì‘ ì¤‘... (ì¬ì‹œì‘ íšŸìˆ˜: {restart_count})")

            pod_id = Config.get_pod_id()
            job_manager = DecentralizedJobManager(pod_id, process_job_async)
            
            # ì „ì—­ job_manager ì„¤ì •
            global _current_job_manager
            _current_job_manager = job_manager
            
            # ê°ì‹œí•  namespace ëª©ë¡
            monitored_namespaces = ['user_story_generator', 'summarizer', 'bounded_context', 'command_readmodel_extractor', 'sitemap_generator']
            
            if Config.is_local_run():
                tasks.append(asyncio.create_task(job_manager.start_job_monitoring(monitored_namespaces)))
                LoggingUtil.info("main", "ì‘ì—… ëª¨ë‹ˆí„°ë§ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                tasks.append(asyncio.create_task(start_autoscaler()))
                tasks.append(asyncio.create_task(job_manager.start_job_monitoring(monitored_namespaces)))
                LoggingUtil.info("main", "ìë™ ìŠ¤ì¼€ì¼ëŸ¬ ë° ì‘ì—… ëª¨ë‹ˆí„°ë§ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            
            # shutdown_event ëª¨ë‹ˆí„°ë§ íƒœìŠ¤í¬ ì¶”ê°€
            shutdown_monitor_task = asyncio.create_task(job_manager.shutdown_event.wait())
            tasks.append(shutdown_monitor_task)
            
            # íƒœìŠ¤í¬ë“¤ ì¤‘ í•˜ë‚˜ë¼ë„ ì™„ë£Œë˜ë©´ ì¢…ë£Œ (shutdown_event í¬í•¨)
            done, pending = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)
            
            # shutdown_eventê°€ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if shutdown_monitor_task in done:
                LoggingUtil.info("main", "Graceful shutdown ì‹ í˜¸ ìˆ˜ì‹ . ë©”ì¸ ë£¨í”„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                
                # ë‚˜ë¨¸ì§€ ì‹¤í–‰ ì¤‘ì¸ íƒœìŠ¤í¬ë“¤ ì·¨ì†Œ
                for task in pending:
                    if not task.done():
                        LoggingUtil.debug("main", f"íƒœìŠ¤í¬ ì·¨ì†Œ ì¤‘: {task}")
                        task.cancel()
                        try:
                            await task
                        except asyncio.CancelledError:
                            LoggingUtil.debug("main", "íƒœìŠ¤í¬ê°€ ì •ìƒì ìœ¼ë¡œ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        except Exception as cleanup_error:
                            LoggingUtil.exception("main", "íƒœìŠ¤í¬ ì •ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ", cleanup_error)
                
                LoggingUtil.info("main", "ë©”ì¸ í•¨ìˆ˜ ì •ìƒ ì¢…ë£Œ")
                break  # while ë£¨í”„ ì¢…ë£Œ
            
        except Exception as e:
            restart_count += 1
            LoggingUtil.exception("main", f"ë©”ì¸ í•¨ìˆ˜ì—ì„œ ì˜ˆì™¸ ë°œìƒ (ì¬ì‹œì‘ íšŸìˆ˜: {restart_count})", e)
            
            # ì‹¤í–‰ ì¤‘ì¸ íƒœìŠ¤í¬ë“¤ ì •ë¦¬
            for task in tasks:
                if not task.done():
                    LoggingUtil.debug("main", f"íƒœìŠ¤í¬ ì·¨ì†Œ ì¤‘: {task}")
                    task.cancel()
                    try:
                        await task
                    except asyncio.CancelledError:
                        LoggingUtil.debug("main", "íƒœìŠ¤í¬ê°€ ì •ìƒì ìœ¼ë¡œ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    except Exception as cleanup_error:
                        LoggingUtil.exception("main", "íƒœìŠ¤í¬ ì •ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ", cleanup_error)

            continue


async def process_summarizer_job(job_id: str, complete_job_func: callable):
    """Summarizer Job ì²˜ë¦¬ í•¨ìˆ˜"""
    error_occurred = None
    try:
        LoggingUtil.info("main", f"ğŸš€ Summarizer ì²˜ë¦¬ ì‹œì‘: {job_id}")
        
        # Job ë°ì´í„° ë¡œë”©
        loop = asyncio.get_event_loop()
        with concurrent.futures.ThreadPoolExecutor() as executor:
            job_path = f'jobs/summarizer/{job_id}'
            job_data = await loop.run_in_executor(
                executor,
                lambda: FirebaseSystem.instance().get_data(job_path)
            )
        
        if not job_data:
            LoggingUtil.warning("main", f"Job ë°ì´í„° ì—†ìŒ: {job_id}")
            return
        
        inputs = job_data.get("state", {}).get("inputs", {})
        if not inputs:
            LoggingUtil.warning("main", f"Job inputs ì—†ìŒ: {job_id}")
            return
        
        # SummarizerWorkflow ì‹¤í–‰
        workflow = RequirementsSummarizerWorkflow()
        result = await asyncio.to_thread(workflow.run, inputs)
        
        summaries = result.get('summarizedRequirements', [])
        LoggingUtil.info("main", f"âœ… ìš”ì•½ ì™„ë£Œ: {len(summaries)}ê°œ")
        
        # ê²°ê³¼ë¥¼ Firebaseì— ì €ì¥
        output_path = f'jobs/summarizer/{job_id}/state/outputs'
        await asyncio.to_thread(
            FirebaseSystem.instance().set_data,
            output_path,
            result
        )
        
        # requestedJob ì‚­ì œ
        req_path = f'requestedJobs/summarizer/{job_id}'
        await asyncio.to_thread(
            FirebaseSystem.instance().delete_data,
            req_path
        )
        
        LoggingUtil.info("main", f"ğŸ‰ ì™„ë£Œ: {job_id}")
        
    except Exception as e:
        error_occurred = e
        LoggingUtil.exception("main", f"Summarizer Job ì²˜ë¦¬ ì˜¤ë¥˜: {job_id}", e)
        
        # ì‹¤íŒ¨ ìƒíƒœ ì €ì¥
        try:
            error_output = {
                "summarizedRequirements": [],
                "isCompleted": False,
                "error": str(e),
                "logs": [{
                    "timestamp": datetime.now().isoformat(),
                    "message": f"ì˜¤ë¥˜: {str(e)}"
                }]
            }
            
            output_path = f'jobs/summarizer/{job_id}/state/outputs'
            await asyncio.to_thread(
                FirebaseSystem.instance().set_data,
                output_path,
                error_output
            )
        except Exception as save_error:
            LoggingUtil.exception("main", f"ì‹¤íŒ¨ ì €ì¥ ì˜¤ë¥˜: {job_id}", save_error)
    
    finally:
        # ì˜ˆì™¸ ë°œìƒ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ complete_job_func í˜¸ì¶œ
        complete_job_func()

async def process_user_story_job(job_id: str, complete_job_func: callable):
    """UserStory Job ì²˜ë¦¬ í•¨ìˆ˜"""
    try:
        LoggingUtil.info("main", f"ğŸš€ UserStory ì²˜ë¦¬ ì‹œì‘: {job_id}")
        
        # Job ë°ì´í„° ë¡œë”© (user_story_generator namespace ì‚¬ìš©)
        loop = asyncio.get_event_loop()
        with concurrent.futures.ThreadPoolExecutor() as executor:
            job_path = f'jobs/user_story_generator/{job_id}'
            job_data = await loop.run_in_executor(
                executor,
                lambda: FirebaseSystem.instance().get_data(job_path)
            )
        
        if not job_data:
            LoggingUtil.warning("main", f"Job ë°ì´í„° ì—†ìŒ: {job_id}")
            return
        
        inputs = job_data.get("state", {}).get("inputs", {})
        if not inputs:
            LoggingUtil.warning("main", f"Job inputs ì—†ìŒ: {job_id}")
            return
        
        # UserStoryWorkflow ì‹¤í–‰
        workflow = UserStoryWorkflow()
        result = await asyncio.to_thread(workflow.run, inputs)
        
        # ê²°ê³¼ëŠ” ì´ë¯¸ camelCaseë¡œ ë³€í™˜ë˜ì–´ ìˆìŒ
        user_stories = result.get('userStories', [])
        actors = result.get('actors', [])
        business_rules = result.get('businessRules', [])
        LoggingUtil.info("main", f"âœ… ìƒì„± ì™„ë£Œ: Stories {len(user_stories)}, Actors {len(actors)}, Rules {len(business_rules)}")
        
        # ê²°ê³¼ë¥¼ Firebaseì— ì €ì¥ (ë¹„ë™ê¸° ì²˜ë¦¬)
        output_path = f'jobs/user_story_generator/{job_id}/state/outputs'
        await asyncio.to_thread(
            FirebaseSystem.instance().set_data,
            output_path,
            result
        )
        
        # requestedJob ì‚­ì œ
        req_path = f'requestedJobs/user_story_generator/{job_id}'
        await asyncio.to_thread(
            FirebaseSystem.instance().delete_data,
            req_path
        )
        
        LoggingUtil.info("main", f"ğŸ‰ ì™„ë£Œ: {job_id}")
        
    except Exception as e:
        LoggingUtil.exception("main", f"ì²˜ë¦¬ ì˜¤ë¥˜: {job_id}", e)
        
        # ì‹¤íŒ¨ ê¸°ë¡
        try:
            error_output = {
                'isFailed': True,
                'error': str(e),
                'progress': 0,
                'userStories': [],  # camelCase
                'logs': [{'timestamp': datetime.now().isoformat(), 'level': 'error', 'message': str(e)}]
            }
            output_path = f'jobs/user_story_generator/{job_id}/state/outputs'
            FirebaseSystem.instance().set_data(output_path, error_output)
        except Exception as save_error:
            LoggingUtil.exception("main", f"ì‹¤íŒ¨ ì €ì¥ ì˜¤ë¥˜: {job_id}", save_error)
    
    finally:
        # ì˜ˆì™¸ ë°œìƒ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ complete_job_func í˜¸ì¶œ
        complete_job_func()

async def process_bounded_context_job(job_id: str, complete_job_func: callable):
    """Bounded Context ìƒì„± Job ì²˜ë¦¬"""
    
    try:
        # Job ë°ì´í„° ë¡œë“œ
        job_path = f'jobs/bounded_context/{job_id}'
        job_data = await asyncio.to_thread(
            FirebaseSystem.instance().get_data,
            job_path
        )
        
        if not job_data:
            LoggingUtil.error("main", f"Job ë°ì´í„° ì—†ìŒ: {job_id}")
            return
        
        # ì…ë ¥ ë°ì´í„° ì¶”ì¶œ (state.inputsì—ì„œ ê°€ì ¸ì˜´)
        state = job_data.get('state', {})
        inputs_data = state.get('inputs', {})
        
        inputs = {
            'devisionAspect': inputs_data.get('devisionAspect', ''),
            'requirements': inputs_data.get('requirements', {}),
            'generateOption': inputs_data.get('generateOption', {}),
            'feedback': inputs_data.get('feedback'),
            'previousAspectModel': inputs_data.get('previousAspectModel')
        }
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        workflow = BoundedContextWorkflow()
        result = await asyncio.to_thread(workflow.run, inputs)
        
        # ê²°ê³¼ ì €ì¥
        output_path = f'jobs/bounded_context/{job_id}/state/outputs'
        await asyncio.to_thread(
            FirebaseSystem.instance().set_data,
            output_path,
            result
        )
        
        # requestedJob ì‚­ì œ
        req_path = f'requestedJobs/bounded_context/{job_id}'
        await asyncio.to_thread(
            FirebaseSystem.instance().delete_data,
            req_path
        )
        
        LoggingUtil.info("main", f"ğŸ‰ BC ìƒì„± ì™„ë£Œ: {job_id}, BCs: {len(result.get('boundedContexts', []))}")
        
    except Exception as e:
        error_occurred = e
        LoggingUtil.exception("main", f"BC ìƒì„± ì˜¤ë¥˜: {job_id}", e)
        
        # ì‹¤íŒ¨ ê¸°ë¡
        try:
            error_output = {
                'isFailed': True,
                'error': str(e),
                'progress': 0,
                'thoughts': '',
                'boundedContexts': [],
                'relations': [],
                'explanations': [],
                'logs': [{'timestamp': datetime.now().isoformat(), 'level': 'error', 'message': str(e)}]
            }
            output_path = f'jobs/bounded_context/{job_id}/state/outputs'
            FirebaseSystem.instance().set_data(output_path, error_output)
        except Exception as save_error:
            LoggingUtil.exception("main", f"ì‹¤íŒ¨ ì €ì¥ ì˜¤ë¥˜: {job_id}", save_error)
    
    finally:
        # ì˜ˆì™¸ ë°œìƒ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ complete_job_func í˜¸ì¶œ
        complete_job_func()

async def process_command_readmodel_job(job_id: str, complete_job_func: callable):
    """Command/ReadModel ì¶”ì¶œ Job ì²˜ë¦¬"""
    
    try:
        LoggingUtil.info("main", f"ğŸš€ Command/ReadModel ì¶”ì¶œ ì‹œì‘: {job_id}")
        
        # Job ë°ì´í„° ë¡œë“œ
        job_path = f'jobs/command_readmodel_extractor/{job_id}'
        job_data = await asyncio.to_thread(
            FirebaseSystem.instance().get_data,
            job_path
        )
        
        if not job_data:
            LoggingUtil.error("main", f"Job ë°ì´í„° ì—†ìŒ: {job_id}")
            return
        
        # ì…ë ¥ ë°ì´í„° ì¶”ì¶œ
        state = job_data.get('state', {})
        inputs_data = state.get('inputs', {})
        
        inputs = {
            'job_id': job_id,
            'requirements': inputs_data.get('requirements', ''),
            'bounded_contexts': inputs_data.get('boundedContexts', []),
            'logs': [],
            'progress': 0,
            'is_completed': False,
            'is_failed': False,
            'error': '',
            'extracted_data': {}
        }
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        workflow = create_command_readmodel_workflow()
        result = await asyncio.to_thread(workflow.invoke, inputs)
        
        # ê²°ê³¼ ì €ì¥
        output_path = f'jobs/command_readmodel_extractor/{job_id}/state/outputs'
        await asyncio.to_thread(
            FirebaseSystem.instance().set_data,
            output_path,
            {
                'extractedData': result.get('extracted_data', {}),
                'logs': result.get('logs', []),
                'progress': result.get('progress', 0),
                'isCompleted': result.get('is_completed', False),
                'isFailed': result.get('is_failed', False),
                'error': result.get('error', '')
            }
        )
        
        # requestedJob ì‚­ì œ
        req_path = f'requestedJobs/command_readmodel_extractor/{job_id}'
        await asyncio.to_thread(
            FirebaseSystem.instance().delete_data,
            req_path
        )
        
        LoggingUtil.info("main", f"ğŸ‰ Command/ReadModel ì¶”ì¶œ ì™„ë£Œ: {job_id}")
        
    except Exception as e:
        error_occurred = e
        LoggingUtil.exception("main", f"Command/ReadModel ì¶”ì¶œ ì˜¤ë¥˜: {job_id}", e)
        
        # ì‹¤íŒ¨ ê¸°ë¡
        try:
            error_output = {
                'isFailed': True,
                'error': str(e),
                'progress': 0,
                'extractedData': {},
                'logs': [{'timestamp': datetime.now().isoformat(), 'level': 'error', 'message': str(e)}]
            }
            output_path = f'jobs/command_readmodel_extractor/{job_id}/state/outputs'
            FirebaseSystem.instance().set_data(output_path, error_output)
        except Exception as save_error:
            LoggingUtil.exception("main", f"ì‹¤íŒ¨ ì €ì¥ ì˜¤ë¥˜: {job_id}", save_error)
    
    finally:
        complete_job_func()

async def process_sitemap_job(job_id: str, complete_job_func: callable):
    """SiteMap ìƒì„± Job ì²˜ë¦¬"""
    
    try:
        LoggingUtil.info("main", f"ğŸš€ SiteMap ìƒì„± ì‹œì‘: {job_id}")
        
        # Job ë°ì´í„° ë¡œë“œ
        job_path = f'jobs/sitemap_generator/{job_id}'
        job_data = await asyncio.to_thread(
            FirebaseSystem.instance().get_data,
            job_path
        )
        
        if not job_data:
            LoggingUtil.error("main", f"Job ë°ì´í„° ì—†ìŒ: {job_id}")
            return
        
        # ì…ë ¥ ë°ì´í„° ì¶”ì¶œ
        state = job_data.get('state', {})
        inputs_data = state.get('inputs', {})
        
        inputs = {
            'job_id': job_id,
            'requirements': inputs_data.get('requirements', ''),
            'bounded_contexts': inputs_data.get('boundedContexts', []),
            'command_readmodel_data': inputs_data.get('commandReadModelData', {}),
            'existing_navigation': inputs_data.get('existingNavigation', []),
            'logs': [],
            'progress': 0,
            'is_completed': False,
            'is_failed': False,
            'error': '',
            'site_map': {}
        }
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        workflow = create_sitemap_workflow()
        result = await asyncio.to_thread(workflow.invoke, inputs)
        
        # ê²°ê³¼ ì €ì¥
        output_path = f'jobs/sitemap_generator/{job_id}/state/outputs'
        await asyncio.to_thread(
            FirebaseSystem.instance().set_data,
            output_path,
            {
                'siteMap': result.get('site_map', {}),
                'logs': result.get('logs', []),
                'progress': result.get('progress', 0),
                'isCompleted': result.get('is_completed', False),
                'isFailed': result.get('is_failed', False),
                'error': result.get('error', '')
            }
        )
        
        # requestedJob ì‚­ì œ
        req_path = f'requestedJobs/sitemap_generator/{job_id}'
        await asyncio.to_thread(
            FirebaseSystem.instance().delete_data,
            req_path
        )
        
        LoggingUtil.info("main", f"ğŸ‰ SiteMap ìƒì„± ì™„ë£Œ: {job_id}")
        
    except Exception as e:
        error_occurred = e
        LoggingUtil.exception("main", f"SiteMap ìƒì„± ì˜¤ë¥˜: {job_id}", e)
        
        # ì‹¤íŒ¨ ê¸°ë¡
        try:
            error_output = {
                'isFailed': True,
                'error': str(e),
                'progress': 0,
                'siteMap': {},
                'logs': [{'timestamp': datetime.now().isoformat(), 'level': 'error', 'message': str(e)}]
            }
            output_path = f'jobs/sitemap_generator/{job_id}/state/outputs'
            FirebaseSystem.instance().set_data(output_path, error_output)
        except Exception as save_error:
            LoggingUtil.exception("main", f"ì‹¤íŒ¨ ì €ì¥ ì˜¤ë¥˜: {job_id}", save_error)
    
    finally:
        complete_job_func()

async def process_job_async(job_id: str, complete_job_func: callable):
    """ë¹„ë™ê¸° Job ì²˜ë¦¬ í•¨ìˆ˜ (Job ID prefixë¡œ ë¼ìš°íŒ…)"""
    
    try:
        LoggingUtil.debug("main", f"Job ì‹œì‘: {job_id}")
        if not JobUtil.is_valid_job_id(job_id):
            LoggingUtil.warning("main", f"Job ì²˜ë¦¬ ì˜¤ë¥˜: {job_id}, ìœ íš¨í•˜ì§€ ì•ŠìŒ")
            return
        
        # Job íƒ€ì…ë³„ ë¼ìš°íŒ… (ê° í•¨ìˆ˜ì—ì„œ finally ë¸”ë¡ìœ¼ë¡œ complete_job_func í˜¸ì¶œ)
        if job_id.startswith("usgen-"):
            await process_user_story_job(job_id, complete_job_func)
        elif job_id.startswith("summ-"):
            await process_summarizer_job(job_id, complete_job_func)
        elif job_id.startswith("bcgen-"):
            await process_bounded_context_job(job_id, complete_job_func)
        elif job_id.startswith("cmrext-"):
            await process_command_readmodel_job(job_id, complete_job_func)
        elif job_id.startswith("smapgen-"):
            await process_sitemap_job(job_id, complete_job_func)
        else:
            LoggingUtil.warning("main", f"ì§€ì›í•˜ì§€ ì•ŠëŠ” Job íƒ€ì…: {job_id}")
            
    except asyncio.CancelledError:
        LoggingUtil.debug("main", f"Job {job_id} ì·¨ì†Œë¨")
        return
        
    except Exception as e:
        LoggingUtil.exception("main", f"Job ì²˜ë¦¬ ì˜¤ë¥˜: {job_id}", e)

if __name__ == "__main__":
    asyncio.run(main())