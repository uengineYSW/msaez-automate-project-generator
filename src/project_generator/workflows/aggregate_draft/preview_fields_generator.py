"""
Preview Fields Generator - LangGraph Backend
ì• ê·¸ë¦¬ê±°íŠ¸ ì´ˆì•ˆì— ëŒ€í•œ í•„ìˆ˜ ì†ì„±(Preview Fields)ì„ ìƒì„±í•˜ëŠ” LangGraph ì›Œí¬í”Œë¡œìš°
"""
from typing import TypedDict, Annotated, List, Dict, Any
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field
import json
from datetime import datetime
from project_generator.utils.logging_util import LoggingUtil


# ==================== Pydantic Models ====================

class PreviewField(BaseModel):
    """ê°œë³„ í•„ë“œ"""
    fieldName: str = Field(..., description="The field name (e.g., user_id, title)")
    refs: List[List[List[Any]]] = Field(..., description="Traceability references in format [[[startLineNumber, 'start_phrase'], [endLineNumber, 'end_phrase']]]")


class AggregateFieldAssignment(BaseModel):
    """ì• ê·¸ë¦¬ê±°íŠ¸ë³„ í•„ë“œ í• ë‹¹"""
    aggregateName: str = Field(..., description="The name of the aggregate")
    previewFields: List[PreviewField] = Field(..., description="List of fields assigned to this aggregate")


class PreviewFieldsOutput(BaseModel):
    """ìµœì¢… ì¶œë ¥ í˜•ì‹"""
    inference: str = Field(..., description="Detailed reasoning for field generation")
    result: Dict[str, List[AggregateFieldAssignment]] = Field(
        ..., 
        description="Result containing aggregateFieldAssignments"
    )


# ==================== State ====================

class PreviewFieldsState(TypedDict):
    """Preview Fields Generatorì˜ ìƒíƒœ"""
    # Input
    description: str
    aggregateDrafts: List[Dict[str, Any]]
    generatorKey: str
    traceMap: Dict[str, Any]
    originalRequirements: str  # ì›ë³¸ ìš”êµ¬ì‚¬í•­ (userStory + ddl)
    
    # Processing
    lineNumberedRequirements: str
    prompt: str
    
    # Output
    inference: str
    aggregateFieldAssignments: List[Dict[str, Any]]
    
    # Metadata
    logs: List[Dict[str, str]]
    progress: int
    isCompleted: bool
    isFailed: bool


# ==================== Preview Fields Generator ====================

class PreviewFieldsGenerator:
    """Preview Fields ìƒì„± ì›Œí¬í”Œë¡œìš°"""
    
    def __init__(self, model_name: str = "gpt-4.1-2025-04-14", temperature: float = 0.7):
        self.model_name = model_name
        self.temperature = temperature
        self.llm = None
        
    def _add_line_numbers(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì— ì¤„ ë²ˆí˜¸ ì¶”ê°€"""
        lines = text.split('\n')
        numbered_lines = []
        for i, line in enumerate(lines, 1):
            numbered_lines.append(f"<{i}>{line}</{i}>")
        return '\n'.join(numbered_lines)
    
    def _get_line_number_range(self, line_numbered_requirements: str) -> tuple:
        """ë¼ì¸ ë²ˆí˜¸ ë²”ìœ„ ê³„ì‚° (í”„ë¡ íŠ¸ì—”ë“œ TextTraceUtil.getLineNumberRangeOfRequirementsì™€ ë™ì¼)"""
        import re
        
        if not line_numbered_requirements:
            return (1, 1)
        
        lines = line_numbered_requirements.strip().split('\n')
        if not lines:
            return (1, 1)
        
        # ì²« ë²ˆì§¸ ë¼ì¸ì—ì„œ ë¼ì¸ ë²ˆí˜¸ ì¶”ì¶œ
        first_line = lines[0]
        first_match = re.match(r'^<(\d+)>', first_line)
        min_line = int(first_match.group(1)) if first_match else 1
        
        # ë§ˆì§€ë§‰ ë¼ì¸ì—ì„œ ë¼ì¸ ë²ˆí˜¸ ì¶”ì¶œ
        last_line = lines[-1]
        last_match = re.match(r'^<(\d+)>', last_line)
        max_line = int(last_match.group(1)) if last_match else len(lines)
        
        return (min_line, max_line)
    
    def _get_line_number_validation_prompt(self, line_numbered_requirements: str) -> str:
        """ë¼ì¸ ë²ˆí˜¸ ê²€ì¦ í”„ë¡¬í”„íŠ¸ ìƒì„± (í”„ë¡ íŠ¸ì—”ë“œ TextTraceUtil.getLineNumberValidationPromptì™€ ë™ì¼)"""
        if not line_numbered_requirements:
            return ''
        
        min_line, max_line = self._get_line_number_range(line_numbered_requirements)
        return f"""
IMPORTANT - LINE NUMBER VALIDATION RULE:
When creating 'refs' arrays in your response, you MUST only use line numbers that exist in the Requirements.
Valid line number range: {min_line} ~ {max_line}
"""
    
    def _build_persona_info(self) -> Dict[str, str]:
        """Persona ì •ë³´ ìƒì„±"""
        return {
            "persona": "Domain-Driven Design (DDD) Field Generation Specialist",
            "goal": "To analyze functional requirements and aggregate draft structures within a bounded context, then intelligently generate appropriate field names for each aggregate based on domain semantics and business logic.",
            "backstory": "With extensive experience in domain modeling and database design, I specialize in translating business requirements into concrete data structures."
        }
    
    def _build_guidelines(self) -> str:
        """ê°€ì´ë“œë¼ì¸ ìƒì„± (í”„ë¡ íŠ¸ì—”ë“œì™€ ë™ì¼)"""
        return """<instruction>
    <core_instructions>
        <title>Aggregate Field Generation Task</title>
        <task_description>Your task is to analyze functional requirements and generate appropriate field names with traceability information for each aggregate draft in a bounded context. Generate comprehensive and semantically correct field sets that accurately represent the data each aggregate should contain according to the business requirements.</task_description>
        
        <input_description>
            <title>You will be given:</title>
            <item id="1">**Functional Requirements:** The business context and domain description for the bounded context with line numbers for traceability</item>
            <item id="2">**Aggregate Drafts:** A list of planned aggregates with their names and basic structure information</item>
        </input_description>

        <guidelines>
            <title>Field Generation Guidelines</title>
            
            <section id="field_generation_rules">
                <title>Field Generation Rules</title>
                <rule id="1">**Business-Driven Generation:** Generate fields that directly support the business operations described in the functional requirements</rule>
                <rule id="2">**Complete Coverage:** Each aggregate should have a comprehensive set of fields that covers its full responsibility scope</rule>
                <rule id="3">**Avoid Duplication:** Each field concept should appear in only one aggregate unless there's a clear business need for duplication</rule>
                <rule id="4">**Domain Semantics:** Field names should reflect the business language and concepts used in the domain</rule>
                <rule id="5">**Consistent Naming:** Use consistent naming patterns across all aggregates (e.g., snake_case, clear prefixes/suffixes)</rule>
            </section>

            <section id="field_categories">
                <title>Standard Field Categories</title>
                <rule id="1">**Identity Fields:** Each aggregate should have a primary identifier (e.g., "user_id", "order_id")</rule>
                <rule id="2">**Core Business Fields:** Fields that represent the main business data for the aggregate</rule>
                <rule id="3">**Lifecycle Fields:** Standard fields like "created_at", "updated_at", "status" where relevant</rule>
                <rule id="4">**Relationship Fields:** Foreign key references to other aggregates when relationships exist</rule>
                <rule id="5">**Metadata Fields:** Additional fields for versioning, auditing, or technical requirements when needed</rule>
            </section>

            <section id="domain_context">
                <title>Domain Context Considerations</title>
                <rule id="1">**Business Operations:** Consider what operations will be performed on each aggregate and what data they require</rule>
                <rule id="2">**State Management:** Include fields needed to track the aggregate's state through its lifecycle</rule>
                <rule id="3">**Business Rules:** Generate fields that support the business rules and constraints mentioned in the requirements</rule>
                <rule id="4">**User Interactions:** Consider what data users will need to view, create, or modify for each aggregate</rule>
            </section>

            <section id="inference_process">
                <title>Inference Process</title>
                <rule id="1">**Domain Analysis:** Begin by understanding the business domain and identifying the core responsibilities of each aggregate</rule>
                <rule id="2">**Extract Data Requirements:** From the functional requirements, identify what data is needed to support the described business operations</rule>
                <rule id="3">**Map Data to Aggregates:** Assign data concepts to the most appropriate aggregate based on business ownership and responsibility</rule>
                <rule id="4">**Apply Domain Language:** Use terminology and naming conventions that match the business domain vocabulary</rule>
                <rule id="5">**Validate Business Logic:** Ensure the generated fields support the business operations and rules described in the requirements</rule>
                <rule id="6">**Document Reasoning:** Clearly explain your field generation decisions, especially for complex or ambiguous cases</rule>
            </section>

            <section id="traceability">
                <title>Source Traceability Requirements</title>
                <rule id="1">**Mandatory Refs:** Each field MUST include a 'refs' array that traces back to specific parts of the functional requirements</rule>
                <rule id="2">**Refs Format:** Use format [[[startLineNumber, "minimal_start_phrase"], [endLineNumber, "minimal_end_phrase"]]]</rule>
                <rule id="3">**Minimal Phrases:** Use 1-2 word phrases that uniquely identify the position in the requirement text</rule>
                <rule id="4">**Valid Line Numbers:** Refs must reference valid line numbers from the provided functional requirements section</rule>
                <rule id="5">**Multiple References:** Multiple reference ranges can be included if a field is derived from multiple requirement sections</rule>
                <rule id="6">**Complete Traceability:** Every generated field must have at least one traceability reference</rule>
            </section>

            <section id="quality">
                <title>Quality Guidelines</title>
                <rule id="1">**Appropriate Granularity:** Generate fields at the right level of detail - not too generic, not overly specific</rule>
                <rule id="2">**Future-Friendly:** Consider reasonable extensions and modifications that might be needed</rule>
                <rule id="3">**Precision and Accuracy:** Be precise in identifying the exact text segments that justify each field</rule>
            </section>
        </guidelines>

        <refs_format_example>
            <title>Example of refs Format for Field Traceability</title>
            <description>If functional requirements contain:</description>
            <example_requirements>
<1># Course Management System</1>
<2></2> 
<3>As an instructor, I want to create and manage my courses. When creating a course, I need to provide a title, description, and price.</3>
<4>Students can enroll in published courses.</4>
<5></5>
<6>## Key Events</6>
<7>- CourseCreated</7>
<8>- CoursePublished</8>
<9>- StudentEnrolled</9>
            </example_requirements>
            <example_refs>
- "course_id" field for Course aggregate â†’ refs: [[[3, "create"], [3, "courses"]]]
- "title" field based on course creation â†’ refs: [[[3, "title"], [3, "price"]]]
- "status" field for course lifecycle â†’ refs: [[[7, "CourseCreated"], [8, "CoursePublished"]]]
- "student_id" field for enrollment â†’ refs: [[[4, "Students"], [9, "StudentEnrolled"]]]
            </example_refs>
            <note>The refs array contains ranges where each range is [[startLine, startPhrase], [endLine, endPhrase]]. Use the shortest possible phrase that can locate the specific part of requirements.</note>
        </refs_format_example>
    </core_instructions>
    
    <output_format>
        <title>JSON Output Format</title>
        <description>The output must be a JSON object structured as follows:</description>
        <schema>
{
    "inference": "(Detailed reasoning for the field generation, including analysis of the domain context and explanation of field choices for each aggregate)",
    "result": {
        "aggregateFieldAssignments": [
            {
                "aggregateName": "(name_of_aggregate)",
                "previewFields": [
                    {
                        "fieldName": "(field_name_1)",
                        "refs": [[[startLineNumber, "minimal start phrase"], [endLineNumber, "minimal end phrase"]]]
                    },
                    {
                        "fieldName": "(field_name_2)",
                        "refs": [[[startLineNumber, "minimal start phrase"], [endLineNumber, "minimal end phrase"]]]
                    }
                ]
            }
        ]
    }
}
        </schema>
        <field_requirements>
            <requirement id="1">All field names must use consistent naming patterns (e.g., snake_case)</requirement>
            <requirement id="2">Every field must include a refs array with valid line number references</requirement>
            <requirement id="3">Aggregate names must match the names provided in the input Aggregate Drafts</requirement>
        </field_requirements>
    </output_format>
</instruction>"""
    
    def _build_prompt(self, state: PreviewFieldsState) -> str:
        """í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        persona = self._build_persona_info()
        guidelines = self._build_guidelines()
        
        aggregates_xml = self._format_aggregates(state['aggregateDrafts'])
        
        # ë¼ì¸ ë²ˆí˜¸ ê²€ì¦ í”„ë¡¬í”„íŠ¸ ì¶”ê°€ (í”„ë¡ íŠ¸ì—”ë“œì™€ ë™ì¼í•˜ê²Œ)
        line_number_validation = self._get_line_number_validation_prompt(state['lineNumberedRequirements'])
        
        prompt = f"""You are a {persona['persona']}.

{persona['goal']}

{guidelines}

{line_number_validation}

## Your Task:
Analyze the following functional requirements and generate appropriate field names with traceability for each aggregate draft.

### Functional Requirements:
{state['lineNumberedRequirements']}

### Aggregate Drafts:
{aggregates_xml}

### Generator Key: {state.get('generatorKey', 'N/A')}

Please generate comprehensive field sets for each aggregate with proper traceability references.
For each field in `previewFields`, include both `fieldName` (English name) and `fieldAlias` (Korean name/alias)."""
        
        return prompt
    
    def _format_aggregates(self, aggregates: List[Dict[str, Any]]) -> str:
        """Aggregate ë¦¬ìŠ¤íŠ¸ë¥¼ XML í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        xml_parts = []
        for agg in aggregates:
            xml_parts.append(f"  <aggregate>")
            xml_parts.append(f"    <name>{agg.get('name', 'Unknown')}</name>")
            if 'alias' in agg:
                xml_parts.append(f"    <alias>{agg['alias']}</alias>")
            xml_parts.append(f"  </aggregate>")
        return "<aggregates>\n" + "\n".join(xml_parts) + "\n</aggregates>"
    
    def _get_response_schema(self) -> Dict[str, Any]:
        """Structured Output ìŠ¤í‚¤ë§ˆ ì •ì˜"""
        return {
            "type": "object",
            "title": "PreviewFieldsOutput",
            "description": "Output format for preview fields generation",
            "properties": {
                "inference": {
                    "type": "string",
                    "description": "Detailed reasoning for the field generation"
                },
                "result": {
                    "type": "object",
                    "properties": {
                        "aggregateFieldAssignments": {
                            "type": "array",
                            "description": "Field assignments for each aggregate",
                            "items": {
                                "type": "object",
                                "properties": {
                                    "aggregateName": {
                                        "type": "string",
                                        "description": "The name of the aggregate"
                                    },
                                    "previewFields": {
                                        "type": "array",
                                        "description": "List of fields for this aggregate",
                                        "items": {
                                            "type": "object",
                                            "properties": {
                                                "fieldName": {
                                                    "type": "string",
                                                    "description": "The field name (English name)"
                                                },
                                                "fieldAlias": {
                                                    "type": "string",
                                                    "description": "The field alias (Korean name)"
                                                },
                                                "refs": {
                                                    "type": "array",
                                                    "description": "Traceability references",
                                                    "minItems": 1,
                                                    "items": {
                                                        "type": "array",
                                                        "items": {
                                                            "type": "array",
                                                            "items": {
                                                                "anyOf": [
                                                                    {"type": "number"},
                                                                    {"type": "string"}
                                                                ]
                                                            }
                                                        }
                                                    }
                                                }
                                            },
                                            "required": ["fieldName", "fieldAlias", "refs"],
                                            "additionalProperties": False
                                        }
                                    }
                                },
                                "required": ["aggregateName", "previewFields"],
                                "additionalProperties": False
                            }
                        }
                    },
                    "required": ["aggregateFieldAssignments"],
                    "additionalProperties": False
                }
            },
            "required": ["inference", "result"],
            "additionalProperties": False
        }
    
    # ==================== Workflow Nodes ====================
    
    def prepare_input(self, state: PreviewFieldsState) -> PreviewFieldsState:
        """ì…ë ¥ ë°ì´í„° ì¤€ë¹„"""
        # Add line numbers to requirements
        description = state.get('description', '')
        state['lineNumberedRequirements'] = self._add_line_numbers(description)
        
        # Build prompt
        state['prompt'] = self._build_prompt(state)
        
        state['logs'] = state.get('logs', [])
        state['logs'].append({
            "message": "Input data prepared",
            "timestamp": datetime.now().isoformat()
        })
        state['progress'] = 10
        
        return state
    
    def generate_fields(self, state: PreviewFieldsState) -> PreviewFieldsState:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ Preview Fields ìƒì„±"""
        aggregates = state.get('aggregateDrafts', [])
        
        try:
            # LLM ì´ˆê¸°í™”
            if not self.llm:
                self.llm = ChatOpenAI(
                    model=self.model_name,
                    temperature=self.temperature
                )
            
            # Structured Output ì„¤ì •
            structured_llm = self.llm.with_structured_output(
                self._get_response_schema(),
                method="json_schema",
                strict=True
            )
            
            # LLM í˜¸ì¶œ
            response = structured_llm.invoke(state['prompt'])
            
            # ì‘ë‹µ ì²˜ë¦¬
            state['inference'] = response.get('inference', '')
            assignments = response.get('result', {}).get('aggregateFieldAssignments', [])
            state['aggregateFieldAssignments'] = assignments
            
            # ìƒì„±ëœ ê²°ê³¼ ë¡œê¹… ë° refs í™•ì¸
            # LLMì´ refsë¥¼ ìƒì„±í–ˆëŠ”ì§€ í™•ì¸
            # Refs ìƒì„± í™•ì¸
            total_fields = 0
            fields_with_refs = 0
            for assignment in assignments:
                for field in assignment.get('previewFields', []):
                    total_fields += 1
                    if field.get('refs') and len(field.get('refs', [])) > 0:
                        fields_with_refs += 1
            if fields_with_refs == 0 and total_fields > 0:
                LoggingUtil.warning("PreviewFieldsGenerator", 
                    "âš ï¸ LLMì´ refsë¥¼ ìƒì„±í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! ìŠ¤í‚¤ë§ˆì— minItems: 1ì´ ì ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸ í•„ìš”")
            
            # ëˆ„ë½ëœ aggregate ê²€ì‚¬
            input_aggregate_names = set(agg.get('name') for agg in aggregates)
            output_aggregate_names = set(a.get('aggregateName') for a in assignments)
            missing_aggregates = input_aggregate_names - output_aggregate_names
            
            if missing_aggregates:
                LoggingUtil.error(
                    "PreviewFieldsGenerator",
                    f"âš ï¸ Missing aggregates in output: {list(missing_aggregates)}"
                )
            
            state['logs'].append({
                "message": f"Generated fields for {len(state['aggregateFieldAssignments'])} aggregates",
                "timestamp": datetime.now().isoformat()
            })
            state['progress'] = 90
            
        except Exception as e:
            LoggingUtil.error("PreviewFieldsGenerator", f"Error generating fields: {str(e)}")
            state['isFailed'] = True
            state['logs'].append({
                "message": f"Error: {str(e)}",
                "timestamp": datetime.now().isoformat()
            })
        
        return state
    
    def finalize_output(self, state: PreviewFieldsState) -> PreviewFieldsState:
        """ìµœì¢… ì¶œë ¥ ì •ë¦¬"""
        
        # refs ë³€í™˜: phrase â†’ index â†’ ì›ë³¸ ë¼ì¸
        # í”„ë¡ íŠ¸ì—”ë“œì™€ ë™ì¼: sanitize/validateëŠ” description ê¸°ì¤€, convertToOriginalRefsUsingTraceMapì€ traceMap ì‚¬ìš©
        description = state.get('description', '')  # BC description (sanitize/validateìš©)
        original_requirements = state.get('originalRequirements', '')  # ì›ë³¸ ìš”êµ¬ì‚¬í•­ (ìµœì¢… ê²€ì¦ìš©)
        line_numbered_requirements = state.get('lineNumberedRequirements', '')
        trace_map = state.get('traceMap', {})
        
        if state.get('aggregateFieldAssignments'):
            self._convert_refs_to_indexes(
                state['aggregateFieldAssignments'],
                description,  # sanitize/validateëŠ” description ê¸°ì¤€ (í”„ë¡ íŠ¸ì—”ë“œì™€ ë™ì¼)
                line_numbered_requirements,
                trace_map,
                original_requirements  # ìµœì¢… ê²€ì¦ìš©
            )
        
        # ê²€ì¦: ê° aggregateê°€ ìµœì†Œí•œì˜ í•„ë“œë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸
        # LLMì´ íŠ¹ì • aggregateì— í•„ë“œë¥¼ ìƒì„±í•˜ì§€ ì•Šì€ ê²½ìš° ì§„ë‹¨ì„ ìœ„í•œ ìƒì„¸ ë¡œê¹…
        input_aggregate_names = set(agg.get('name') for agg in state.get('aggregateDrafts', []))
        output_aggregate_names = set()
        
        for assignment in state.get('aggregateFieldAssignments', []):
            aggregate_name = assignment.get('aggregateName', 'Unknown')
            output_aggregate_names.add(aggregate_name)
            preview_fields = assignment.get('previewFields', [])
            
            if not preview_fields or len(preview_fields) == 0:
                # ìƒì„¸ ì§„ë‹¨ ì •ë³´ ë¡œê¹…
                LoggingUtil.warning("PreviewFieldsGenerator", 
                    f"Aggregate '{aggregate_name}' has no generated fields. "
                    f"Input aggregates: {sorted(input_aggregate_names)}, "
                    f"Output aggregates: {sorted(output_aggregate_names)}, "
                    f"Total assignments: {len(state.get('aggregateFieldAssignments', []))}. "
                    f"í”„ë¡œì„¸ìŠ¤ë¥¼ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
                
                # LLM ì‘ë‹µ ì›ë³¸ í™•ì¸
                if state.get('inference'):
                    LoggingUtil.debug("PreviewFieldsGenerator", 
                        f"Inference for '{aggregate_name}': {state['inference'][:500]}...")
                
                # ê²½ê³ ë§Œ ë¡œê¹…í•˜ê³  í”„ë¡œì„¸ìŠ¤ ê³„ì† ì§„í–‰ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì²˜ë¦¬)
                state['logs'].append({
                    "message": f"Aggregate '{aggregate_name}' has no generated fields (ê²½ê³ )",
                    "timestamp": datetime.now().isoformat(),
                    "level": "warning"
                })
                # í”„ë¡œì„¸ìŠ¤ ì¤‘ë‹¨í•˜ì§€ ì•Šê³  ê³„ì† ì§„í–‰
                continue
            
            # ê° í•„ë“œì˜ refs ê²€ì¦
            for field in assignment.get('previewFields', []):
                if not field.get('refs') or len(field.get('refs', [])) == 0:
                    LoggingUtil.warning("PreviewFieldsGenerator", 
                        f"Field '{field.get('fieldName', 'unknown')}' in aggregate '{assignment.get('aggregateName', 'unknown')}' has empty refs")
        
        state['isCompleted'] = True
        state['progress'] = 100
        state['logs'].append({
            "message": "Preview fields generation completed",
            "timestamp": datetime.now().isoformat()
        })
        
        return state
    
    def _restore_trace_map(self, trace_map):
        """Firebaseê°€ ë°°ì—´ë¡œ ë³€í™˜í•œ traceMapì„ ê°ì²´ë¡œ ë³µì›"""
        if not trace_map:
            return {}
        
        # ì´ë¯¸ ê°ì²´ í˜•íƒœì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
        if isinstance(trace_map, dict) and not isinstance(trace_map, list):
            # ë¬¸ìì—´ í‚¤ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë˜, ìˆ«ì í‚¤ë¡œë„ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ ì–‘ìª½ ëª¨ë‘ ì €ì¥
            # (í”„ë¡ íŠ¸ì—”ë“œ RefsTraceUtil.convertToOriginalRefsUsingTraceMapì—ì„œ traceMap[i] || traceMap[String(i)]ë¡œ ì ‘ê·¼)
            normalized_trace_map = {}
            for key, value in trace_map.items():
                normalized_trace_map[key] = value
                # ìˆ«ìë¡œ ë³€í™˜ ê°€ëŠ¥í•˜ë©´ ìˆ«ì í‚¤ë¡œë„ ì €ì¥ (ì–‘ìª½ ëª¨ë‘ ì ‘ê·¼ ê°€ëŠ¥)
                try:
                    num_key = int(key)
                    if str(num_key) == str(key):
                        normalized_trace_map[num_key] = value
                except (ValueError, TypeError):
                    pass
            return normalized_trace_map
        
        # ë°°ì—´ í˜•íƒœì¸ ê²½ìš° ë³€í™˜
        restored_trace_map = {}
        if isinstance(trace_map, list):
            for index, item in enumerate(trace_map):
                if not item:
                    continue
                # {"key":"4","value":{...}} í˜•íƒœì¸ ê²½ìš°
                if isinstance(item, dict) and 'key' in item and 'value' in item:
                    key = item['key']
                    restored_trace_map[str(key)] = item['value']
                    # ìˆ«ìë¡œ ë³€í™˜ ê°€ëŠ¥í•˜ë©´ ìˆ«ì í‚¤ë¡œë„ ì €ì¥ (ì–‘ìª½ ëª¨ë‘ ì ‘ê·¼ ê°€ëŠ¥)
                    try:
                        num_key = int(key)
                        if str(num_key) == str(key):
                            restored_trace_map[num_key] = item['value']
                    except (ValueError, TypeError):
                        pass
                else:
                    # Firebaseê°€ ë¹„ì—°ì† ìˆ«ì í‚¤ ê°ì²´ë¥¼ ë°°ì—´ë¡œ ë³€í™˜í•œ ê²½ìš°
                    # ë°°ì—´ ì¸ë±ìŠ¤ê°€ ì›ë˜ í‚¤ì™€ ì¼ì¹˜í•¨ (ì˜ˆ: ì¸ë±ìŠ¤ 4 = ì›ë˜ í‚¤ "4")
                    # Noneì´ ì•„ë‹Œ í•­ëª©ì˜ ì¸ë±ìŠ¤ë¥¼ í‚¤ë¡œ ì‚¬ìš©
                    if isinstance(item, dict):
                        # ì¸ë±ìŠ¤ë¥¼ í‚¤ë¡œ ì‚¬ìš© (ë¬¸ìì—´ê³¼ ìˆ«ì ëª¨ë‘ ì €ì¥)
                        restored_trace_map[index] = item
                        restored_trace_map[str(index)] = item
        
        return restored_trace_map
    
    def _convert_refs_to_indexes(
        self,
        aggregate_field_assignments: List[Dict],
        description: str,  # BC description (sanitize/validateìš©)
        line_numbered_requirements: str,
        trace_map: Dict,
        original_requirements: str = ''  # ì›ë³¸ ìš”êµ¬ì‚¬í•­ (ìµœì¢… ê²€ì¦ìš©, ì„ íƒì )
    ) -> None:
        """refsë¥¼ phrase â†’ indexesë¡œ ë³€í™˜ (í”„ë¡ íŠ¸ì—”ë“œ RefsTraceUtilê³¼ ë™ì¼)"""
        from project_generator.workflows.aggregate_draft.traceability_generator import TraceabilityGenerator
        
        # ë””ë²„ê¹…: ì…ë ¥ ìƒíƒœ í™•ì¸
        LoggingUtil.info("PreviewFieldsGenerator", 
            f"ğŸ” [ë³€í™˜ ì‹œì‘] description ê¸¸ì´={len(description) if description else 0}, "
            f"line_numbered_requirements ê¸¸ì´={len(line_numbered_requirements) if line_numbered_requirements else 0}, "
            f"trace_map keys={len(trace_map) if isinstance(trace_map, dict) else 0 if trace_map else 0}")
        
        if not description:
            LoggingUtil.warning("PreviewFieldsGenerator", 
                "âš ï¸ descriptionì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
        
        if not line_numbered_requirements:
            LoggingUtil.error("PreviewFieldsGenerator", 
                "âŒ line_numbered_requirementsê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤! ë³€í™˜ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
            return
        
        # traceMap ë³µì› (Firebaseê°€ ë°°ì—´ë¡œ ë³€í™˜í•œ ê²½ìš° ì²˜ë¦¬)
        restored_trace_map = self._restore_trace_map(trace_map)
        
        # TraceabilityGeneratorì˜ ë³€í™˜ ë©”ì„œë“œ ì¬ì‚¬ìš©
        temp_generator = TraceabilityGenerator()
        
        total_fields = 0
        converted_fields = 0
        failed_fields = 0
        sanitize_failed = 0
        validate_failed = 0
        trace_map_failed = 0
        
        from project_generator.utils.refs_trace_util import RefsTraceUtil
        
        def convert_field_refs(field, field_type='previewFields'):
            """ë‹¨ì¼ í•„ë“œì˜ refs ë³€í™˜ (previewFieldsì™€ previewAttributes ê³µí†µ)"""
            if 'refs' not in field or not field['refs']:
                return False
            
            nonlocal total_fields, converted_fields, failed_fields, sanitize_failed, validate_failed, trace_map_failed
            total_fields += 1
            original_refs = field['refs']
            
            # ì²« ë²ˆì§¸ í•„ë“œë§Œ ìƒì„¸ ë¡œê¹…
            is_first = total_fields == 1
            
            try:
                # 1. sanitizeAndConvertRefs: phrase â†’ [[[line, col], [line, col]]]
                if is_first:
                    LoggingUtil.info("PreviewFieldsGenerator", 
                        f"ğŸ” [sanitize ì‹œë„] field='{field.get('fieldName', 'unknown')}', "
                        f"original_refs={original_refs[:1] if original_refs else []}")
                
                sanitized_data = RefsTraceUtil.sanitize_and_convert_refs(
                    {'refs': original_refs},
                    line_numbered_requirements,
                    is_use_xml_base=True
                )
                sanitized_refs = sanitized_data.get('refs', original_refs) if isinstance(sanitized_data, dict) else sanitized_data
                
                if not sanitized_refs:
                    if is_first:
                        LoggingUtil.warning("PreviewFieldsGenerator", 
                            f"âŒ [sanitize ì‹¤íŒ¨] field='{field.get('fieldName', 'unknown')}', "
                            f"original_refs={original_refs[:1] if original_refs else []}, "
                            f"sanitized_data={sanitized_data}")
                    sanitize_failed += 1
                    failed_fields += 1
                    return False
                
                if is_first:
                    LoggingUtil.info("PreviewFieldsGenerator", 
                        f"âœ… [sanitize ì„±ê³µ] field='{field.get('fieldName', 'unknown')}', "
                        f"sanitized_refs={sanitized_refs[:1] if sanitized_refs else []}")
                
                field['refs'] = sanitized_refs
                
                # 2. validateRefs: ë²”ìœ„ ê²€ì¦ (description ê¸°ì¤€, í”„ë¡ íŠ¸ì—”ë“œì™€ ë™ì¼)
                try:
                    temp_generator._validate_refs(field['refs'], description)
                except Exception as e:
                    if is_first:
                        LoggingUtil.warning("PreviewFieldsGenerator", 
                            f"âŒ [validate ì‹¤íŒ¨] field='{field.get('fieldName', 'unknown')}', "
                            f"error={str(e)}, sanitized_refs={sanitized_refs[:1] if sanitized_refs else []}")
                    validate_failed += 1
                    # ì›ë³¸ refsë¡œ ë³µì›
                    field['refs'] = original_refs
                    failed_fields += 1
                    return False
                
                # 3. convertToOriginalRefsUsingTraceMap: traceMap ì‚¬ìš©í•´ ì›ë³¸ ë¼ì¸ìœ¼ë¡œ ì—­ë³€í™˜
                if restored_trace_map:
                    converted_refs = RefsTraceUtil.convert_to_original_refs_using_trace_map(
                        field['refs'],
                        restored_trace_map
                    )
                    
                    if not converted_refs:
                        if is_first:
                            LoggingUtil.warning("PreviewFieldsGenerator", 
                                f"âŒ [traceMap ë³€í™˜ ì‹¤íŒ¨] field='{field.get('fieldName', 'unknown')}', "
                                f"sanitized_refs={sanitized_refs[:1] if sanitized_refs else []}")
                        trace_map_failed += 1
                        # ë³€í™˜ ì‹¤íŒ¨ ì‹œ sanitized_refs ìœ ì§€
                        field['refs'] = sanitized_refs
                        failed_fields += 1
                        return False
                    else:
                        if is_first:
                            LoggingUtil.info("PreviewFieldsGenerator", 
                                f"âœ… [ë³€í™˜ ì™„ë£Œ] field='{field.get('fieldName', 'unknown')}', "
                                f"converted_refs={converted_refs[:1] if converted_refs else []}")
                        field['refs'] = converted_refs
                        converted_fields += 1
                        return True
                else:
                    # trace_mapì´ ì—†ìœ¼ë©´ sanitized_refs ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    converted_fields += 1
                    return True
                    
            except Exception as e:
                if is_first:
                    LoggingUtil.error("PreviewFieldsGenerator", 
                        f"âŒ [ì˜ˆì™¸ ë°œìƒ] field='{field.get('fieldName', 'unknown')}', "
                        f"error={str(e)}")
                # ì›ë³¸ refs ìœ ì§€
                field['refs'] = original_refs
                failed_fields += 1
                return False
        
        for assignment in aggregate_field_assignments:
            # previewFields ë³€í™˜
            for field in assignment.get('previewFields', []):
                convert_field_refs(field, 'previewFields')
            
            # previewAttributes ë³€í™˜ (previewFieldsì™€ ë™ì¼í•œ êµ¬ì¡°)
            for field in assignment.get('previewAttributes', []):
                convert_field_refs(field, 'previewAttributes')
        
        if failed_fields > 0:
            LoggingUtil.warning("PreviewFieldsGenerator", 
                f"Refs ë³€í™˜: {converted_fields}/{total_fields} ì„±ê³µ, {failed_fields} ì‹¤íŒ¨ "
                f"(sanitize: {sanitize_failed}, validate: {validate_failed}, traceMap: {trace_map_failed})")
    
    # ==================== Workflow Construction ====================
    
    def create_workflow(self) -> StateGraph:
        """ì›Œí¬í”Œë¡œìš° ìƒì„±"""
        workflow = StateGraph(PreviewFieldsState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("prepare_input", self.prepare_input)
        workflow.add_node("generate_fields", self.generate_fields)
        workflow.add_node("finalize_output", self.finalize_output)
        
        # ì—£ì§€ ì¶”ê°€
        workflow.set_entry_point("prepare_input")
        workflow.add_edge("prepare_input", "generate_fields")
        workflow.add_edge("generate_fields", "finalize_output")
        workflow.add_edge("finalize_output", END)
        
        return workflow.compile()
    
    def run(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        
        # ì´ˆê¸° ìƒíƒœ ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œ ì—ì´ì „íŠ¸ ë°©ì‹ê³¼ ë™ì¼í•˜ê²Œ descriptionë§Œ ì‚¬ìš©)
        initial_state: PreviewFieldsState = {
            'description': input_data.get('description', ''),
            'aggregateDrafts': input_data.get('aggregateDrafts', []),
            'generatorKey': input_data.get('generatorKey', 'default'),
            'traceMap': input_data.get('traceMap', {}),
            'originalRequirements': input_data.get('originalRequirements', ''),  # ì›ë³¸ ìš”êµ¬ì‚¬í•­ (userStory + ddl)
            'lineNumberedRequirements': '',
            'prompt': '',
            'inference': '',
            'aggregateFieldAssignments': [],
            'logs': [],
            'progress': 0,
            'isCompleted': False,
            'isFailed': False
        }
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        workflow = self.create_workflow()
        final_state = workflow.invoke(initial_state)
        
        # ê²°ê³¼ ë°˜í™˜
        return {
            'inference': final_state.get('inference', ''),
            'aggregateFieldAssignments': final_state.get('aggregateFieldAssignments', []),
            'logs': final_state.get('logs', []),
            'progress': final_state.get('progress', 0),
            'isCompleted': final_state.get('isCompleted', False),
            'isFailed': final_state.get('isFailed', False)
        }

